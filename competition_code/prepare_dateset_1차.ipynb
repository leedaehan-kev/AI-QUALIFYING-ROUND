{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1e2ed757",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as ss\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "eb3c0c4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train  = pd.read_csv('competition_data/train.csv')\n",
    "test  = pd.read_csv('competition_data/test.csv')\n",
    "## Input Feature - Target 분리\n",
    "##train_x = train.drop(['nerdiness', 'index'],axis=1)   ## Input Feature 값\n",
    "##train_y = train['nerdiness']     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6e5a00b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test 문항에 대한 Column\n",
    "test_cols = ['Q1','Q2','Q3','Q4','Q5','Q6','Q7','Q8','Q9','Q10',\n",
    "             'Q11','Q12','Q13','Q14','Q15','Q16','Q17','Q18','Q19','Q20',\n",
    "             'Q21','Q22', 'Q23','Q24','Q25','Q26']\n",
    "\n",
    "## 응시 시간 문항에 대한 Column\n",
    "time_cols = ['introelapse', 'testelapse', 'surveyelapse']\n",
    "\n",
    "## TIPI 문항에 대한 Column\n",
    "tipi_cols = ['TIPI1','TIPI2','TIPI3','TIPI4','TIPI5','TIPI6','TIPI7','TIPI8',\n",
    "             'TIPI9','TIPI10']\n",
    "\n",
    "vcl_exist = ['VCL1','VCL2','VCL3','VCL4','VCL5','VCL7','VCL8','VCL10','VCL11','VCL13','VCL14','VCL15','VCL16']\n",
    "vcl_no_exist = ['VCL6','VCL9','VCL12']\n",
    "## VCL 문항에 대한 Column\n",
    "vcl_cols = vcl_exist + vcl_no_exist\n",
    "\n",
    "## 설문문항에 대한 Column\n",
    "survy_cols = ['country','education','urban','gender','engnat','age','hand','religion',\n",
    "              'orientation','voted','married','familysize','ASD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5265d0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eraseOutlis(dframe):\n",
    "    tmp_frame = dframe.copy()\n",
    "    tmp_no_outli = tmp_frame[tmp_frame['age'] < 100]\n",
    "    \n",
    "    intr_92q = tmp_no_outli['introelapse'].quantile(q=0.92,interpolation='nearest')\n",
    "    tmp_no_outli=tmp_no_outli[tmp_no_outli['introelapse'] < intr_92q]\n",
    "    \n",
    "    ## testelapse 하위0.04% 미만의 값을 갖는 Row 들 전부 삭제\n",
    "    test_004q = tmp_no_outli['testelapse'].quantile(q=0.0004,interpolation='nearest')\n",
    "    tmp_no_outli=tmp_no_outli[tmp_no_outli['testelapse'] >= test_004q]\n",
    "\n",
    "    ## surveyelapse 하위 0.2% 미만의 값을 갖는 Row 들 전부 삭제\n",
    "    srvy_04q = tmp_no_outli['surveyelapse'].quantile(q=0.002,interpolation='nearest')\n",
    "    tmp_no_outli=tmp_no_outli[tmp_no_outli['surveyelapse'] >= srvy_04q]\n",
    "\n",
    "    ## familysize 에 극단적으로 큰값(2919) 를 갖는 Row 제거\n",
    "    tmp_no_outli=tmp_no_outli[tmp_no_outli['familysize'] < 39]\n",
    "    \n",
    "    return tmp_no_outli\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a1f0118d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_no_outli = eraseOutlis(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f0f89ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replaceNAN(dframe):\n",
    "    continuous_nan = ['age','introelapse','testelapse','surveyelapse']             ## 연속형 변수\n",
    "    norminal_nan = list(dframe.columns.values)                         \n",
    "    for cont in continuous_nan:\n",
    "        norminal_nan.remove(cont)\n",
    "        \n",
    "    tmp_frame = dframe.copy()\n",
    "    ## 연속형 변수들에 대해서는 평균값으로 대체\n",
    "    tmp_frame[continuous_nan] = tmp_frame[continuous_nan].fillna(round(tmp_frame[continuous_nan].mean()))\n",
    "    ## 이산형 변수들에 대해서는 최빈값으로 대체\n",
    "    tmp_frame[norminal_nan] =tmp_frame[norminal_nan].fillna(tmp_frame[norminal_nan].mode().iloc[0].squeeze())\n",
    "    return tmp_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5c87711e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_no_outli_nan = replaceNAN(train_no_outli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "316a4258",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcTIPI(dframe):\n",
    "    tp_enc = dframe.copy()\n",
    "    tp_enc['tp_extra'] = (dframe['TIPI1'] + (8-dframe['TIPI6']))/2 ## 외향성 \n",
    "    tp_enc['tp_agree'] = (dframe['TIPI7'] + (8-dframe['TIPI2']))/2 ## 친화성\n",
    "    tp_enc['tp_consc'] = (dframe['TIPI3'] + (8-dframe['TIPI8']))/2 ## 성실성\n",
    "    tp_enc['tp_emoti'] = (dframe['TIPI9'] + (8-dframe['TIPI4']))/2 ## 정서적 안정성\n",
    "    tp_enc['tp_opens'] = (dframe['TIPI5'] + (8-dframe['TIPI10']))/2 ## 경험에 대한 개방성\n",
    "    \n",
    "    return tp_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "33028755",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addColumn(dframe):\n",
    "    tmp_frame=dframe.copy()\n",
    "    tmp_frame['test_score'] = dframe[test_cols].sum(axis=1)\n",
    "    tmp_frame['exist_know'] = dframe[vcl_exist].sum(axis=1)\n",
    "    tmp_frame['mean_test'] = dframe[['testelapse']].sum(axis=1)/26   ## 테스트 문항 별 평균적 응답시간 추가\n",
    "    tmp_frame['mean_srvy'] = dframe[['surveyelapse']].sum(axis=1)/39 ## 설문 문항 별 평균적 응답시간 추가\n",
    "    #tmp_frame['age_log'] = np.log(dframe['age'])                   ## age 에 로그를 취하여, 정규화\n",
    "    tmp_frame = calcTIPI(tmp_frame)\n",
    "    \n",
    "    return tmp_frame\n",
    "\n",
    "def dropColumn(dframe):\n",
    "    drop_Qs = test_cols.copy()\n",
    "    drop_Qs.remove('Q15')\n",
    "    drop_Qs.remove('Q25')\n",
    "    droplist =  drop_Qs + ['familysize','age','orientation','hand','married','ASD'] + vcl_cols + tipi_cols + time_cols\n",
    "    tmp_frame = dframe.copy()\n",
    "    tmp_frame = tmp_frame.drop(droplist, axis=1)\n",
    "    return tmp_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "00f7901a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 이상치 제거, 결측치 처리된 Dataframe 대상으로 새로운 Column 들 추가 후, 기존 일부 Column들 제거\n",
    "train_final_add = addColumn(train_no_outli_nan)\n",
    "train_final_drop = dropColumn(train_final_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6c653ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ratio_table(cross_tab):\n",
    "    return cross_tab.div(cross_tab.sum(axis=1),axis='index')\n",
    "\n",
    "def groupCntryCol(dframe):\n",
    "    tmp_country = train[['country','nerdiness']].dropna()\n",
    "    native_country_table=tmp_country['country'].value_counts()\n",
    "    country_count = tmp_country['country'].unique().shape[0]\n",
    "    \n",
    "    country_crosstab=pd.crosstab(tmp_country['country'],tmp_country['nerdiness'])\n",
    "    country_crossgtab_res=ss.chi2_contingency(country_crosstab)\n",
    "    \n",
    "    country_ratio=ratio_table(country_crosstab)\n",
    "    country_ratio=country_ratio.sort_values(by=0)\n",
    "    \n",
    "    prob_dict=dict(country_ratio[1])\n",
    "    \n",
    "    cntry_group1=[]\n",
    "    cntry_group2=[]\n",
    "    cntry_group3=[]\n",
    "    cntry_group4=[]\n",
    "\n",
    "    for country in tmp_country['country'].unique():\n",
    "        country_data=tmp_country[tmp_country['country']==country]['nerdiness']\n",
    "        probs=sum(country_data)/country_data.count()\n",
    "        if probs <= 1 and probs >=0.6:\n",
    "            cntry_group1.append(country)\n",
    "        elif probs >=0.4 and probs <0.6:\n",
    "            cntry_group2.append(country)\n",
    "        elif probs >= 0.2 and probs < 0.4:\n",
    "            cntry_group3.append(country)\n",
    "        else:\n",
    "            cntry_group4.append(country)\n",
    "    #print(country,probs)\n",
    "    return (cntry_group1, cntry_group2, cntry_group3, cntry_group4)\n",
    "\n",
    "\n",
    "def groupCountry(dframe,group):\n",
    "    tmp_frame = dframe.copy()\n",
    "    \n",
    "    tmp_frame['country']=tmp_frame['country'].replace(group[0],0)\n",
    "    tmp_frame['country']=tmp_frame['country'].replace(group[1],1)\n",
    "    tmp_frame['country']=tmp_frame['country'].replace(group[2],2)\n",
    "    tmp_frame['country']=tmp_frame['country'].replace(group[3],3)\n",
    "    \n",
    "    return tmp_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1f7fda2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cntry_group1, cntry_group2, cntry_group3, cntry_group4 = groupCntryCol(train_final_drop)\n",
    "train_final_grouped = groupCountry(train_final_drop, (cntry_group1, cntry_group2, cntry_group3, cntry_group4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9961423c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(dframe):\n",
    "    tmp_frame = dframe.copy()\n",
    "    categorical_cols = ['country','urban','gender','engnat','religion','voted']\n",
    "    \n",
    "    for col in categorical_cols:\n",
    "        col_ohe = pd.get_dummies(tmp_frame[col], prefix=col)\n",
    "        tmp_frame = pd.concat((tmp_frame, col_ohe), axis=1).drop(col, axis=1)\n",
    "    return tmp_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a2075fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final_ohe = one_hot_encoding(train_final_grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3605a8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stdize_cols(dframe):\n",
    "    tmp_frame =dframe.copy()\n",
    "    col_stdize = ['mean_test', 'mean_srvy']\n",
    "    scaler = StandardScaler()\n",
    "    numeric_df = pd.DataFrame(scaler.fit_transform(tmp_frame[col_stdize]),columns=col_stdize,index=tmp_frame.index)\n",
    "    X_train_new = tmp_frame.drop(columns=col_stdize)\n",
    "    train_final_ohe_stdize =pd.concat([numeric_df,X_train_new],axis=1)\n",
    "    return train_final_ohe_stdize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5bed076f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final_ohe_stdize = stdize_cols(train_final_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d43b5409",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_test(dframe):\n",
    "    test_frame =dframe.copy()\n",
    "    test_no_outli = eraseOutlis(test_frame)\n",
    "    test_no_outli_nan = replaceNAN(test_no_outli)\n",
    "    \n",
    "    test_final = addColumn(test_no_outli_nan)\n",
    "    test_final = dropColumn(test_final)\n",
    "    test_final= groupCountry(test_final,(cntry_group1, cntry_group2, cntry_group3, cntry_group4))\n",
    "    \n",
    "    test_final_ohe = one_hot_encoding(test_final)\n",
    "    test_final_ohe_stdize = stdize_cols(test_final_ohe)\n",
    "    \n",
    "    return test_final_ohe_stdize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "95aeb2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pre = prepare_test(test)                   ## 타겟 변수값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "192ac792",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train.drop(['nerdiness', 'index'],axis=1)   ## Input Feature 값\n",
    "train_y = train['nerdiness']   \n",
    "\n",
    "test_x = test_pre.drop(['index'],axis=1)   ## Input Feature 값"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "myvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
